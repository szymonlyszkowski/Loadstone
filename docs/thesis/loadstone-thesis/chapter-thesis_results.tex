\chapter{Thesis results}

\section{Overview}
The main purpose of this thesis is to obtain categorization system for POIs. Such task is complex and difficult to execute for complex data which are present in modern word. It is very difficult to obtain desired results for each kind of data. Text processing is wide domain and requires a lot of computing power and time to return results which are readable for human. When some heuristics is applied processing effort can be decreased in both fields of execution time and required computing power. As mentioned in previous chapters there are many methods which enable method categorization. What is more every method is aimed for different kind of input data. This can indicate that initial knowledge about input data is absolutely compulsory to achieve desired effect and effectiveness. In this chapter the results obtained from implemented information system will be presented for delivered source of data which is Loadstone database.

\section{Customized semi-supervised classification for Loadstone database}
\label{analyze_db}
Frequency for bag of words was prepared using bash shell script using \textit{awk} tool which is great utility for text analysis \cite{21}. Script traverses through the Loadstone database text file and counts occurrence of each word which exists in document. Algorithm can be expressed in following way:
\begin{algorithm}[h]
	\KwData{All words existing in Loadstone database text file}
	\KwResult{Number of occurrences for each word}
	initialize array \textbf{words[]};
	\newline
	\ForEach{ \textit{word} in text file}
	{
		transform \textit{word} to lower case (avail disambiguation)
		\newline
		increase value by one for index \textit{word} in array \textbf{words[]} 
	}
	\ForEach{\textit{index-word} in \textbf{words[]}}{
		\Return word frequency:\textbf{words[\textit{index-word}]} for \textit{index-word} 	
	}
	\caption{Analysing frequency of words in database}
	\label{alg:analyze_freuency}
\end{algorithm}

Basing on Algorithm \ref{alg:analyze_freuency} it was possible to easily define those phrases which were most occurring and were significant or absolutely unnecessary for text categorization. Obtaining list of words with their occurrences in document there could be selected which can be used in BOW and which can be used for preprocessing as a hint.

\section{Preprocessing results}
Preprocessing is a task which does not involve high level of complexity in text analysis. It is very important to consider all combinations of \textit{\textbf{field separators}}(this therm denotes sign of space between analysed words). Usually it is \textit{space} sign but not always. As already mentioned this may vary among input data and such signs could be \textit{tab key} or \textit{\_} sign. The best idea to apply text preprocessing is to collect statistics which would give information which phrases could be easily applied on data without any regression and conflicts on results. In case of Loadstone database special bash script was prepared which is described in chapter section: \ref{analyze_db}. Results of this script gave heuristics which could be applied for preprocessing.
Phrases which can be rejected from analysed text without any bothering about categorization correctness are as follows:
\newline
\begin{itemize}
	\item \textbf{\textit{"ul"}}
	\item \textbf{\textit{"adres"}}
	\item \textbf{\textit{"."}}
\end{itemize}
Phrase \textit{"ul"} occurred respectively \textbf{98378} table \ref{tab1} \textbf{872770} table \ref{tab2} - the most frequently and does not say about any category. Phrase \textit{"."} is a dot so definitely does not have any significant influence on categorization result. Moreover such removal will ease future categorization. Phrase \textit{"adres"} occurred \textbf{759337} table \ref{tab2}. This number was obtained from text file containing all data available for Loadstone project. There is a test suite in \textit{loadstone.api.classification.loadstone.LoadstonePreprocessingTest} class which presents execution of preprocessing on specially prepared DataModel's for this purpose. Results for analysed texts with those particular patterns to be rejected from input text are as follows:

\begin{algorithm}
	\SetAlgorithmName{Example}{}
	
	\KwData{\textit{\textbf{"adres ul ul. fake name to be trimmed "}}}
	\KwResult{\textit{\textbf{"fake name to be trimmed"}}}
	\hfill \break
	\caption{Preprocessing example using mocked data}
	\label{alg:1st}
\end{algorithm}

This example shows that phrases: \textit{"adres ul ul. " and " "} were successfully rejected and there is significantly less data to analyse in further categorization process.
\newline
Another example is taken directly from Loadstone database. Preprocessed text is an Loadstone database entry.
\begin{algorithm}
	\SetAlgorithmName{Example}{}
	
	\KwData{\textit{\textbf{"adres ul. kramarska 15 warszawa rembertów"}}}
	\KwResult{\textit{\textbf{"kramarska 15 warszawa rembertów"}}}
	\hfill \break
	\caption{Preprocessing example using data extracted from Loadstone database}
	\label{alg:2nd}
\end{algorithm}
\newline
As it is noticeable also in this case preprocessing was successful and did not rejected any data important from categorization point of view. Phrase: \textit{"adres ul. "} was trimmed correctly.
 
  
\section{Classification results}
\label{classification_results}
\subsection{Overview}
Classification is much more complicated task than preprocessing. It involves complex analysis of input data, possible misconceptions or not precise heuristics. Moreover, categorization usually should be unambiguous but not always. Sometimes POI can be classified to more than one category as an example there can be considered a \textit{\textbf{church}} which can be categorized as \textit{"U - Activities of extraterritorial organisations and bodies "}(according to NACE standard notation) or may as well classified as \textit{"R - Arts, entertainment and recreation "}. However what is worth to mention is correlation between those two categories. POI \textit{\textbf{church}} cannot always be classified as the latter but always as the first one. Such cases can be complex and perfect solution is unlikely to find as well. The correctness of classification results may also vary among judging human beings.

    
\subsection{Naive classifier categorization results}
As mentioned in section: \ref{naive_classifier} naive classification bases on heuristics inherited from NACE standard. As heuristic for unambiguous results it takes information about frequency of given phrase in NACE category description. When one heuristic overcome in frequency second heuristic the latter is rejected. Two of more categories as result are returned when frequency is the same for each of given heuristic. When heuristic is not available in input data classification is unavailable. The following example can be presented for imaginary data:
\begin{algorithm}
	\SetAlgorithmName{Example}{}
	
	\KwData{\textit{\textbf{"Manufacturing Manufacturing Manufacturing Manufacturing Manufacturing Manufacturing administration administration administration"}}}
	\KwResult{\textit{\textbf{"C - Manufacturing "}}}
	\hfill \break
	\caption{Naive classifier example using mocked data for different phrase frequency}
	\label{alg:3rd}
\end{algorithm}
\newline
As heuristic \textbf{\textit{"Manufacturing"}} frequency was higher than \textbf{\textit{"administration"}} (six occurrences versus three occurrences) category C is returned as result for categorization system.
\newline
Another example demonstrate naive classification when heuristic frequency has the same value of occurrences for each component:
\begin{algorithm}
	\SetAlgorithmName{Example}{}
	
	\KwData{\textit{\textbf{"Manufacturing Manufacturing Manufacturing administration administration administration"}}}
	\KwResult{\textit{\textbf{"C - Manufacturing ", "O - Public administration and defence; compulsory social security "}}}
	\hfill \break
	\caption{Naive classifier example using mocked data for uniform phrase frequency}
	\label{alg:4th}
\end{algorithm}
\newline  
As heuristic \textbf{\textit{"Manufacturing"}} frequency was the same as heuristic \textbf{\textit{"administration"}} category C and O is returned as result for categorization system.

\subsubsection{Naive classifier for Loadstone database}

As heuristic is suit to data which are definitely not included in Loadstone database input data description (main issue is comparison between English and polish language) naive classifier does not have significant utility during Loadstone database analysis. Example \ref{alg:6th} proves it:
\begin{algorithm}
	\SetAlgorithmName{Example}{}
	
	\KwData{\textit{\textbf{"bankomat i oddział bz bwk atm 24h bank ul. jana pawła ii 12 sieradz"}}}
	\KwResult{\textit{\textbf{"Not classified"}}}
	\hfill \break
	\caption{Naive classifier using data extracted from Loadstone database}
	\label{alg:5th}
\end{algorithm}
\newline  
As none heuristic exists in input data from NACE categories description "Not classified" result is returned.
\newline
\textit{Note: all examples are implemented as test suite of unit tests in class\newline loadstone.api.classification.NaiveClassifierTest}    
\subsection{Semisupervised categorization for Loadstone database results}
Semisupervised categorization is very useful but requires much more complex analysis. It requires knowledge about heuristics included in input data. To perform semi-supervised categorization Loadstone bag of words was prepared previously (description chapter section: \ref{loadstone_bow}). Thanks to initial knowledge what kind of phrases could be used for categorization, results correctness is decent. Important factor is complete isolation from heuristics included in NACE standard category description (such approach could possibly introduce regression). Following examples demonstrates performance of semi-supervised categorization intended deliberately for input data derived from Loadstone database:
\newline
\begin{algorithm}[h]
	\SetAlgorithmName{Example}{}
	
	\KwData{\textit{\textbf{"bankomat i oddział bz bwk atm 24h bank ul. jana pawła ii 12 sieradz"}}}
	\KwResult{\textit{\textbf{"K - Financial and insurance activities "}}}
	\hfill \break
	\caption{Semi-supervised categorization using data extracted from Loadstone database}
	\label{alg:6th}
\end{algorithm}
\newline
Because of heuristics: \textbf{\textit{bankomat, atm, bank}} which are defined in Loadstone BOW are all assigned to category K unambiguous result is retrieved. This sample clearly demonstrates difference between naive (example: \ref{alg:5th}) and semi-supervised classification. Naive classification is basing on heuristic taken from description of NACE categories table: \ref{tab:NaceMatching}. Input data were in completely different (Polish language) than heuristic (English language). Possible improvement for this case could be NACE categories description to Polish language.  
\newline
\begin{algorithm}[h]
	\SetAlgorithmName{Example}{}
	
	\KwData{\textit{\textbf{"bankomat and pizza"}}}
	\KwResult{\textit{\textbf{"I - Accommodation and food service activities ", "K - Financial and insurance activities "}}}
	\hfill \break
	\caption{Semi-supervised categorization using mocked data with uniform phrase frequency}
	\label{alg:7th}
\end{algorithm}
\newline
Because of heuristics: \textbf{\textit{bankomat, pizza}} which are defined in Loadstone BOW but are assigned to different categories the result is ambiguous. Heuristics frequencies are equal so two categories are returned as categorization results.
\newline
There was also performed comparison of imaginary data indicated deliberately to NACE standard category description analysed by using method of semi-supervised categorization. The result is as follows:
\begin{algorithm}[h]
	\SetAlgorithmName{Example}{}
	
	\KwData{\textit{\textbf{"Manufacturing Manufacturing Manufacturing Manufacturing Manufacturing Manufacturing administration administration administration"}}}
	\KwResult{\textit{\textbf{"Not classified"}}}
	\hfill \break
	\caption{Semi-supervised categorization using mocked data not related to Loadstone BOW}
	\label{alg:8th}
\end{algorithm}
\newline
In comparison to example \ref{alg:3rd} obtained result is completely irrelevant to reality and does not give correct result.
\newline 
\textit{Note: all examples are implemented as test suite of unit tests in class \newline loadstone.api.classification.LoadstoneSemiSupervisedClassifierTest}

\subsubsection{Database analysis results}
In order to construct suitable semi-supervised categorization there was performed database analysis. Analysis was done using \textit{bash} shell script \textbf{analyzeDB.sh}. Script enables whole database analysis. The result of such analysis is number occurrences of phrases separated by white space. Text file analysed was: \cite{29}. During script execution there was processed \textbf{37549} different phrases. Execution of the script took: \textbf{2.937 sec.} Results of ten most frequent phrases are depicted in table \ref{tab1}.
\begin{table}[H]
	\centering
	\begin{tabular}{ | c | c |}
		\hline
		Occurrences & Phrase\tabularnewline \hline
		98378 & ul.	\\
		11153 & "wysokość\\
		11117 & "bankomat\\
		9105  & "parking\\
		8914  & "kościół\\
		7517  & i\\
		6999  & "kurier\\
		6959  & pgp\\
		6691  & 1 \\
		6072  & 24h\\
		5569  & "szkoła\\		
		\hline
	\end{tabular}
	\caption{Descending phrase occurrence frequencies all addresses}
	\label{tab1}
\end{table}
Results of of ten most frequent phrases occurrences for text file containing only POIs are depicted in table \ref{tab2}. Execution of the script took: \textbf{24.274sec.}
\begin{table}[H]
	\centering
	\begin{tabular}{ | c | c |}
		\hline
		Occurrences & Phrase\\ \hline		
		872770& ul.\\
		759337& "adres\\
		296042& "skrzyż.\\
		102080& warszawa\\
		53792& wrocław\\
		45019& kraków\\
		35939& 1\\
		34733& 3\\
		30102& "dzielnica\\
		29675& 2	\\	
		\hline
	\end{tabular}
	\caption{Descending phrase occurrence frequencies POIs}
	\label{tab2}
\end{table}
Obviously not all of them were included in bag of words for semi-supervised classification. All words with adjusted category were chosen empirically. In total to Loadstone bag of words there was included \textbf{72} words.

\section{Naive and semi-supervised classification comparison}
Two categorization methods which were implemented in Java library and are delivered through API may appear to be similar to each other. Both of them are using somehow defined heuristics and return result in form of previously defined category. Main which distinguish this methods is heuristic definition. In case of \textbf{naive classification} heuristic is imposed from very beginning. User does not have any influence on the form of given classification tips. In case of Java library implementation this may appear to be a drawback because tips for classification are defined in English language. However, naive method disqualify source data which are not defined in English language (such situation is presented in example \ref{alg:8th}). Possible solution would be to translate NACE categories description (table \ref{tab:NaceMatching}) to other languages. This may result in higher naive classification correctness. Naive classification details are described in section \ref{naive_classifier} . On the other hand user does not have to apply any hints for classification. \textbf{Semi-supervised} heuristic can be defined by user. If user performed analysis of input data before classification e.g. phrases frequency occurrence (like in case of this thesis) and defined internal BOW, results correctness should increase (as there not exists categorization method which would enable more accurate classification than human being). Additionally, initial BOW definition solves issue of input data language - human beings are able to define keywords hints for every language. Semi-supervised classification details are presented in section \ref{semi_desc}. This two methods present different approach to classification problem solution and should be used depending on the form of input data and user involvement.
 
\section{Performance results}
Performance was measured for one hundred iterations of classification method invokes. Additionally to assure results correctness five iterations were added at the beginning as a warm-up. During performance measurement time of data access to database was discarded. Performance results only reveal time of implemented classification and preprocessing methods.
\begin{itemize}
	\item Preprocessing performance results are presented in table \ref{tabPreprocessing}. 
	\begin{table}[H]
	\centering
	\begin{tabular}{ | c | c | c | c |}
		\hline
		Operation & Time & Error & Unit\\ \hline		
		\textbf{Example \ref{alg:1st}} & 0,003 & 0,001 & ms/op \\
		\textbf{Example \ref{alg:2nd}} & 0,002 & 0,001 & ms/op \\		
		\hline
	\end{tabular}
	\caption{Preprocessing performance results}
	\label{tabPreprocessing}
	\end{table}
	\item Naive classifier performance results are presented in table \ref{tabNaive}.
	\begin{table}[H]
	\centering
	\begin{tabular}{ | c | c | c | c |}
		\hline
		Operation & Time & Error & Unit\\ \hline		
		\textbf{Example \ref{alg:3rd}} & 0,004 &  0,001 & ms/op \\
		\textbf{Example \ref{alg:4th}} & 0,003 &  0,001 & ms/op \\
		\textbf{Example \ref{alg:5th}} & 0,007 &  0,001 & ms/op \\
		\hline
	\end{tabular}
	\caption{Naive classifier performance results}
	\label{tabNaive}
\end{table}
	\item Semisupervised categorization results are presented in table \ref{tabSemi}.
		\begin{table}[H]
			\centering
			\begin{tabular}{ | c | c | c | c |}
				\hline
				Operation & Time & Error & Unit\\ \hline		
				\textbf{Example \ref{alg:6th}} & 0,001 &  0,001 & ms/op \\
				\textbf{Example \ref{alg:7th}} & 0,002 &  0,001 & ms/op \\
				\textbf{Example \ref{alg:8th}} & 0,003 &  0,001 & ms/op \\
					\hline
				\end{tabular}
				\caption{Semi-supervised categorization performance results}
				\label{tabSemi}
			\end{table}
\end{itemize}
As performance results states the worst case scenario is when there is applied categorization method which is not intended for given kind of data (example \ref{alg:5th}). The rest of results are on quite same level and does not cost much. Even worst case scenario is quite cheap solution for modern mobile devices and computers as all results are expressed in milliseconds. The biggest concern during consideration of presented test cases should be I/O time operation. This factor was not included as it was not purpose of this thesis. On the other hand when considering functionality and performance of whole information system this factor requires further investigation.

\subsubsection{Hardware used for performance testing}
All tests were executed on notebook with hardware parameters: CPU - Intel Core i7-4702MQ, 16 GB RAM, Graphic Card - GeForce GT 740M, HDD Hard Drive.
    
\section{Conclusion}
The purpose of this thesis was to provide overview of categorization methods using text analysis which can be useful during POI classification. As a result of this research there was developed Loadstone database (using script \textit{createDB.sh}), Java library which delivers interface for \textit{Loadstone} database access and provides categorization methods mainly customized for data included in database. Such customization was possible thanks to automatic analysis of phrase frequencies in database which functionality enables script \textit{analyzeDB.sh}. Library can be useful when developing applications using GPS systems to deliver information about POI in the neighbourhood. Main benefit of library is independence on data source so using specially designed interface there is possibility to deliver many kind of data sources and combine it in one application. The topic of POI categorization is wide and complex domain. This domain mainly involves text processing and heuristics about possible hints which can be used to obtain expected results. As presented in chapter section \ref{classification_results} result may differ according to applied categorization method. A lot of factors need to be considered when categorization task is applied like: language of input data, model of input data (it is possible to analyse whole documents or large fragment of texts or ready to use databases), size of input data (performance in complex information systems is one of significant factor). It is really difficult challenge to estimate what kind heuristics data can be obtained and work out system which would be versatile for every data source. Another important factor is choice of technology for such information system. Java possess high native library support and community as well \cite{24}\cite{25}. Unfortunately this involves a lot of research in Internet to find suitable collection which can be used in implementation. What is more it is often practice that code construction is getting more complex and difficult to maintain in future. Example of such practice is returning classification result as \textit{list of categories} instead of using construction called \textit{tuple}. Such constructions are available in programming languages like: \textit{Scala} \cite{26} or \textit{Python} \cite{27}. What is more syntax of those programming languages is easier to read (it is possible to omit long-line Java syntax - not so huge effort is pushed on object encapsulation) and flexibility. Another important issue are external tools which could be used for easier maintenance of information system. Such tool could be \textit{Apache Spark} \cite{28}. It increases the performance of execution and is great manager for feature extraction, transformations or SVM. On the other hand this technology is quite new and requires significant effort at the beginning to use it.     